{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc_Hxz0uTziP"
   },
   "source": [
    "# **Trainig and using YOLOv8 for road surface segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjMP2CCIde64",
    "outputId": "ba6b110b-5c24-4102-d9d0-63d2005ad906"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade pip\n",
    "!pip install --quiet ultralytics\n",
    "!pip install --quiet torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial variables setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "naXrkCoA5xfr",
    "outputId": "995937d2-a4c8-4785-83db-edad38bfb437"
   },
   "outputs": [],
   "source": [
    "# If you want to use a previously trained model\n",
    "I_want_to_use_an_already_trained_model = True\n",
    "path_to_the_trained_yolov8_model = 'models/yolov8_road_segmentation/weights/best.pt'\n",
    "\n",
    "\n",
    "# If you want to train a YOLOv8 model\n",
    "dataset_dir = '/home/nibio/my_desk/roadsens/model_training/datasets/roadsens/roadsens_published_dataset/'\n",
    "data_yaml=f\"{dataset_dir}/data.yaml\"\n",
    "dir_name_to_save_the_results= \"yolov8_road_segmentation\"\n",
    "\n",
    "yolov8_model_size = \"nano\"        # options: [\"nano\", \"small\", \"medium\", \"large\", \"xlarge\"]\n",
    "task_of_the_model = \"segment\"     # options: [\"detect\", \"segment\"]\n",
    "\n",
    "treat_all_classes_as_one_class = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIXhmrfKg3Tq"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "if I_want_to_use_an_already_trained_model:\n",
    "  try:\n",
    "    model = YOLO(path_to_the_trained_yolov8_model)\n",
    "    print(f\"The model: {path_to_the_trained_yolov8_model} loaded.\")\n",
    "  except:\n",
    "    print(f\"Could not load the model: {path_to_the_trained_yolov8_model}.\\nA YOLOv8 {yolov8_model_size} will be used.\")\n",
    "    if task_of_the_model.lower() == \"segment\":\n",
    "      model = YOLO(f\"yolov8{yolov8_model_size[0].lower()}-seg.yaml\")\n",
    "    elif (task_of_the_model.lower() == \"detect\"):\n",
    "      model = YOLO(f\"yolov8{yolov8_model_size[0].lower()}.yaml\") \n",
    "else:\n",
    "  if task_of_the_model.lower() == \"segment\":\n",
    "    model = YOLO(f\"yolov8{yolov8_model_size[0].lower()}-seg.yaml\") \n",
    "  elif (task_of_the_model.lower() == \"detect\"):\n",
    "    model = YOLO(f\"yolov8{yolov8_model_size[0].lower()}.yaml\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4pOyAEjuFtw"
   },
   "source": [
    "### <a name=\"yolo_training_params\"></a>Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "3iPXqvhouGOf"
   },
   "outputs": [],
   "source": [
    "image_size = 640\n",
    "batch = 12 \n",
    "epochs=2000  \n",
    "\n",
    "intersect_over_union_for_accepting_a_detection = 0.95 \n",
    "use_dataset_augmentation = True \n",
    "\n",
    "model.train(data=data_yaml,\n",
    "            imgsz=image_size,\n",
    "            batch=batch,\n",
    "            epochs=epochs,\n",
    "            name=dir_name_to_save_the_results,\n",
    "            exist_ok=False,\n",
    "            iou=intersect_over_union_for_accepting_a_detection,\n",
    "            single_cls=treat_all_classes_as_one_class,\n",
    "            augment=use_dataset_augmentation,\n",
    "            translate= 0.5,\n",
    "            scale= 0.9,\n",
    "            mixup=0.3) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yGAcccLjNYn"
   },
   "source": [
    "**Validating the trained model on the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIupCkvqjSvM"
   },
   "outputs": [],
   "source": [
    "metrics = model.val(split=\"test\",data=data_yaml, single_cls=treat_all_classes_as_one_class, name=dir_name_to_save_the_results+\"_on_test_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PATikyd2lAb"
   },
   "source": [
    "<br>\n",
    "\n",
    "### Using the model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "nkzFZf2x2tea"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_or_folder_to_apply_the_model_for_prediction = \"/home/nibio/my_desk/roadsens/model_training/datasets/roadsens/roadsens_published_dataset/test/images\" \n",
    "\n",
    "if os.path.exists(file_or_folder_to_apply_the_model_for_prediction):\n",
    "  res = model.predict(source=file_or_folder_to_apply_the_model_for_prediction,\n",
    "                      save=True,\n",
    "                      save_txt=True, show_labels=False, line_width=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "roadsens_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a7a54e36411c4c298ecc7bb7d845e3e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e78ab690a20841b3b40f91093dfdf4f5": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_a7a54e36411c4c298ecc7bb7d845e3e5",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span></pre>\n",
         "text/plain": "\u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
